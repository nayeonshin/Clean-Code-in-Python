{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch8. 단위테스트와 리팩토링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[reference](https://www.slideshare.net/hosunglee948/python-52222334)\n",
    "## 단워 테스트(Unit Test)\n",
    "- 개발자 뷰\n",
    "- 함수 단위\n",
    "- Mock 을 사용\n",
    "- 빠름\n",
    "- 코드의 품질 향상\n",
    "\n",
    "## 기능 테스트(Function Test)\n",
    "- 사용자 뷰\n",
    "- 요구사항 단위\n",
    "- Fixture를 사용\n",
    "- 느림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 디자인 원칙과 단위 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단위 테스트란 다른 코드의 유효성을 검사하는 코드\n",
    "- 비즈니스 로직이 특정 조건을 보장하는 지를 확인하기 위해 여러 시나리오를 검증하는 코드\n",
    "  - 격리:  비즈니스로직에만 집중하고 다른 외부 에이전트와 독립되어야 함(DB, HTTP emd)\n",
    "  - 성능: 빠르게\n",
    "  - 자체 검증: 단위 테스트의 실행만으로 결과를 결정할 수 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected type str for metric_value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SSAFY_~1\\AppData\\Local\\Temp/ipykernel_15508/2993659434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_iterations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SSAFY_~1\\AppData\\Local\\Temp/ipykernel_15508/2993659434.py\u001b[0m in \u001b[0;36mprocess_iterations\u001b[1;34m(self, n_iterations)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iteration.{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SSAFY_~1\\AppData\\Local\\Temp/ipykernel_15508/2993659434.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, metric_name, metric_value)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected type str for metric_value\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sending %s = %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected type str for metric_value"
     ]
    }
   ],
   "source": [
    "# ut_design_1\n",
    "\n",
    "import logging\n",
    "import random\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MetricsClient:\n",
    "    \"\"\"3rd-party metrics client\"\"\"\n",
    "\n",
    "    def send(self, metric_name, metric_value):\n",
    "        if not isinstance(metric_name, str):\n",
    "            raise TypeError(\"expected type str for metric_name\")\n",
    "\n",
    "        if not isinstance(metric_value, str):\n",
    "            raise TypeError(\"expected type str for metric_value\")\n",
    "\n",
    "        logger.info(\"sending %s = %s\", metric_name, metric_value)\n",
    "\n",
    "\n",
    "# class Process:\n",
    "#     \"\"\"A job that runs in iterations, and depends on an external object.\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.client = MetricsClient()  # A 3rd-party metrics client\n",
    "\n",
    "#     def process_iterations(self, n_iterations):\n",
    "#         for i in range(n_iterations):\n",
    "#             result = self.run_process()\n",
    "#             self.client.send(\"iteration.{}\".format(i), result)\n",
    "\n",
    "#     def run_process(self):\n",
    "#         return random.randint(1, 100)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     Process().process_iterations(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:sending iteration.0 = 62\n",
      "INFO:__main__:sending iteration.1 = 34\n",
      "INFO:__main__:sending iteration.2 = 31\n",
      "INFO:__main__:sending iteration.3 = 59\n",
      "INFO:__main__:sending iteration.4 = 82\n",
      "INFO:__main__:sending iteration.5 = 54\n",
      "INFO:__main__:sending iteration.6 = 37\n",
      "INFO:__main__:sending iteration.7 = 97\n",
      "INFO:__main__:sending iteration.8 = 2\n",
      "INFO:__main__:sending iteration.9 = 17\n"
     ]
    }
   ],
   "source": [
    "# ut_design_2\n",
    "\n",
    "class WrappedClient:\n",
    "    \"\"\"An object under our control that wraps the 3rd party one.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = MetricsClient()\n",
    "\n",
    "    def send(self, metric_name, metric_value):\n",
    "        return self.client.send(str(metric_name), str(metric_value))\n",
    "\n",
    "\n",
    "class Process:\n",
    "    \"\"\"Same process, now using a wrapper object.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = WrappedClient()\n",
    "\n",
    "    def process_iterations(self, n_iterations):\n",
    "        for i in range(n_iterations):\n",
    "            result = self.run_process()\n",
    "            self.client.send(\"iteration.{}\".format(i), result)\n",
    "\n",
    "    def run_process(self):\n",
    "        return random.randint(1, 100)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Process().process_iterations(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ut_design_2\n",
    "\n",
    "from unittest import TestCase, main\n",
    "from unittest.mock import Mock\n",
    "\n",
    "from ut_design_2 import WrappedClient\n",
    "\n",
    "\n",
    "class TestWrappedClient(TestCase):\n",
    "    def test_send_converts_types(self):\n",
    "        wrapped_client = WrappedClient()\n",
    "        wrapped_client.client = Mock()\n",
    "        wrapped_client.send(\"value\", 1)\n",
    "\n",
    "        wrapped_client.client.send.assert_called_with(\"value\", \"1\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단위테스트와 소프트웨어 디자인\n",
    "- 단위테스트는 자기 코드에 동작에 대한 증거이자 안정망\n",
    "- 테스트의 용이성은 클린 코드의 핵심 가치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 테스트를 위한 프레임워크와 도구\n",
    "## unittest\n",
    "- 표준 라이브러리\n",
    "- 테스트 시나리오 다룰 때 사용\n",
    "## pytest\n",
    "- pip 설치 라이브러리 \n",
    "- 외부 시스템에 연결하는 등의 의존성이 많은 경우 테스트 케이스를 파라미터화할 수 있는 픽스터(fixture)라는 패치 객체 필요\n",
    "- 이 때 pytest 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrstatus import MergeRequestException\n",
    "from mrstatus import MergeRequestExtendedStatus as MergeRequestStatus\n",
    "\n",
    "class MergeRequest:\n",
    "    def __init__(self):\n",
    "        self._context = {\"upvotes\": set(), \"downvotes\": set()}\n",
    "        self._status = MergeRequestStatus.OPEN\n",
    "\n",
    "    def close(self):\n",
    "        self._status = MergeRequestStatus.CLOSED\n",
    "\n",
    "    @property\n",
    "    def status(self):\n",
    "        if self._status == MergeRequestStatus.CLOSED:\n",
    "            return self._status\n",
    "\n",
    "        if self._context[\"downvotes\"]:\n",
    "            return MergeRequestStatus.REJECTED\n",
    "        elif len(self._context[\"upvotes\"]) >= 2:\n",
    "            return MergeRequestStatus.APPROVED\n",
    "        return MergeRequestStatus.PENDING\n",
    "\n",
    "    def _cannot_vote_if_closed(self):\n",
    "        if self._status == MergeRequestStatus.CLOSED:\n",
    "            raise MergeRequestException(\"can't vote on a closed merge request\")\n",
    "\n",
    "    def upvote(self, by_user):\n",
    "        self._cannot_vote_if_closed()\n",
    "\n",
    "        self._context[\"downvotes\"].discard(by_user)\n",
    "        self._context[\"upvotes\"].add(by_user)\n",
    "\n",
    "    def downvote(self, by_user):\n",
    "        self._cannot_vote_if_closed()\n",
    "\n",
    "        self._context[\"upvotes\"].discard(by_user)\n",
    "        self._context[\"downvotes\"].add(by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrstatus import MergeRequestException\n",
    "from mrstatus import MergeRequestExtendedStatus as MergeRequestStatus\n",
    "\n",
    "\n",
    "class MergeRequest:\n",
    "    def __init__(self):\n",
    "        self._context = {\"upvotes\": set(), \"downvotes\": set()}\n",
    "        self._status = MergeRequestStatus.OPEN\n",
    "\n",
    "    def close(self):\n",
    "        self._status = MergeRequestStatus.CLOSED\n",
    "\n",
    "    @property\n",
    "    def status(self):\n",
    "        if self._status == MergeRequestStatus.CLOSED:\n",
    "            return self._status\n",
    "\n",
    "        if self._context[\"downvotes\"]:\n",
    "            return MergeRequestStatus.REJECTED\n",
    "        elif len(self._context[\"upvotes\"]) >= 2:\n",
    "            return MergeRequestStatus.APPROVED\n",
    "        return MergeRequestStatus.PENDING\n",
    "\n",
    "    def _cannot_vote_if_closed(self):\n",
    "        if self._status == MergeRequestStatus.CLOSED:\n",
    "            raise MergeRequestException(\"can't vote on a closed merge request\")\n",
    "\n",
    "    def upvote(self, by_user):\n",
    "        self._cannot_vote_if_closed()\n",
    "\n",
    "        self._context[\"downvotes\"].discard(by_user)\n",
    "        self._context[\"upvotes\"].add(by_user)\n",
    "\n",
    "    def downvote(self, by_user):\n",
    "        self._cannot_vote_if_closed()\n",
    "\n",
    "        self._context[\"upvotes\"].discard(by_user)\n",
    "        self._context[\"downvotes\"].add(by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedCases:\n",
    "    \"\"\"For the MRs that use the extended status.\"\"\"\n",
    "\n",
    "    def test_cannot_upvote_on_closed_merge_request(self):\n",
    "        self.merge_request.close()\n",
    "        self.assertRaises(\n",
    "            MergeRequestException, self.merge_request.upvote, \"dev1\"\n",
    "        )\n",
    "\n",
    "    def test_cannot_downvote_on_closed_merge_request(self):\n",
    "        self.merge_request.close()\n",
    "        self.assertRaisesRegex(\n",
    "            MergeRequestException,\n",
    "            \"can't vote on a closed merge request\",\n",
    "            self.merge_request.downvote,\n",
    "            \"dev1\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytest\n",
    "- assert 구문을 사용해 조건을 검사하는 것이 가능\n",
    "- 재사용 가능한 기능을 쉽게 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 픽스처(Fixture)\n",
    "- 테스트 사전/사후에 사용 가능한 리소스 또는 모듈\n",
    "- `@pytest.fixture`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드 커버리지\n",
    "- test runner는 pip를 통해 설치 가능한 커버리지 플러그인을 제공\n",
    "- 커버리지 플러그인은 코드의 어떤 부분이 실행되었는지 알려줌\n",
    "- converage 라이브러리\n",
    "- pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pytest \\\n",
    "> --cov-report term-missing \\\n",
    "> --cov=coverage_1 \\\n",
    "> test_coverage_1.py \n",
    "================== test session starts ==================\n",
    "platform win32 -- Python 3.9.7, pytest-6.2.5, py-1.10.0, pluggy-1.0.0\n",
    "rootdir: C:\\Users\\ssafy_eunseong\\Desktop\\CleanCodeinPython_Code\\Chapter08\n",
    "plugins: anyio-3.3.4, Faker-9.3.1, cov-3.0.0\n",
    "collected 16 items\n",
    "\n",
    "test_coverage_1.py ................                [100%]\n",
    "\n",
    "----------- coverage: platform win32, python 3.9.7-final-0 -----------\n",
    "Name            Stmts   Miss  Cover   Missing\n",
    "---------------------------------------------\n",
    "coverage_1.py      39      1    97%   44\n",
    "---------------------------------------------\n",
    "TOTAL              39      1    97%\n",
    "\n",
    "\n",
    "================== 16 passed in 0.39s =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "높은 커버리지만으로 해당 코드에 대해 품질을 보증할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모의(Mock) 객체\n",
    "- 원하지 않는 부작용으로부터 테스트 코드를 보호하는 가장 좋은 방법 중 하나 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09037bb3da3403e9ea7d45129c0b9a6b15d0ce6b6bb372b4204088a5f425237c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
